{
	"name": "Bkn_invertertable_v1_time_Batch_test",
	"properties": {
		"description": "This code is written to read daily Parquet files and perform the transformation to create Table for Inverters' Performance.",
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkpool1",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "a9963208-78e4-4c4a-bbac-527cd2299151"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/37a47312-6f04-42dc-ad99-290d950fab5d/resourceGroups/AzureSynapse/providers/Microsoft.Synapse/workspaces/azure-synapse-devlop/bigDataPools/sparkpool1",
				"name": "sparkpool1",
				"type": "Spark",
				"endpoint": "https://azure-synapse-devlop.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.1",
				"nodeCount": 10,
				"cores": 8,
				"memory": 56,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**INVERTER TABLE WITH VARIOUS DAY-LEVEL FEATURES LIKE: Energy, SpY, Donwtime, Wake-UpTime, SleepTime, EnergyLost, Efficiency**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd \n",
					"import datetime\n",
					"import numpy as np\n",
					"import matplotlib.pyplot as plt\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import *\n",
					"import pyspark.sql.functions as sf\n",
					"from datetime import datetime \n",
					"from datetime import date \n",
					"from datetime import timedelta\n",
					"# from pyspark.sql.functions import to_date\n",
					"from datetime import time\n",
					"import pytz\n",
					"from pathlib import Path\n",
					"#import pymsteams\n",
					"import warnings\n",
					"warnings.filterwarnings(\"ignore\")"
				],
				"execution_count": 222
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Static_file_PV_Syst_location='abfss://nucleus@ayanadatalake.dfs.core.windows.net/Bkn_StaticFiles/AxonBkn_PVSyst.xlsx'\r\n",
					"Static_file_loss_Calculation=\"abfss://nucleus@ayanadatalake.dfs.core.windows.net/Bkn_StaticFiles/Bikaner_Static_for_loss_Calculation.xlsx\"\r\n",
					"Tag='abfss://devlop@ayanadatalake.dfs.core.windows.net/Bikaner/Bkn_Tables.xlsx'  \r\n",
					"sheet_name=\"Table2\""
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#pattoreadparquet = \"abfss://repono@ayanadatalake.dfs.core.windows.net/allcsvtoparquet/dt=\"\n",
					"LoopCounter=1\n",
					"tz = pytz.timezone('Asia/Kolkata')\n",
					"todaydate = datetime.date(datetime.now(tz))\n",
					"print(todaydate)\n",
					"mintime = datetime.min.time()\n",
					"DateList =[]\n",
					"while LoopCounter <= 1 :\n",
					"    DateList.append( datetime.date ( (datetime.combine(todaydate, mintime) - timedelta(days=LoopCounter)) ))\n",
					"    LoopCounter += 1\n",
					"DateListLength = len(DateList)\n",
					"print(DateList)\n",
					"TableLoopCounter = 0\n",
					"DateLoopCounter = 0"
				],
				"execution_count": 223
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pathtoreadcsv = [\"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_opcda/\"]\n",
					"#pattoreadcsv_b = \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4841_b/\"\n",
					"#pattoreadcsv_c = \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4841_c/\"\n",
					"#pattoreadcsv_d = \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4841_d/\"\n",
					"#pattoreadcsv_a2 = \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4842_a/\"\n",
					"#pattoreadcsv_b2= \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4842_b/\"\n",
					"#pattoreadcsv_c2 = \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4842_c/\"\n",
					"#pattoreadcsv_d2 = \"abfss://bikanerrealtime@ayanadatalake.dfs.core.windows.net/bikaner_realtime_4842_d/\"\n",
					"LoopCounter=1\n",
					"tz = pytz.timezone('Asia/Kolkata')\n",
					"todaydate = datetime.date(datetime.now(tz))\n",
					"print(todaydate)\n",
					"mintime = datetime.min.time()\n",
					"DateList =[]\n",
					"while LoopCounter <= 1 :\n",
					"    DateList.append( datetime.date ( (datetime.combine(todaydate, mintime) - timedelta(days=LoopCounter)) ))\n",
					"    LoopCounter += 1\n",
					"DateListLength = len(DateList)\n",
					"print(DateList)\n",
					"TableLoopCounter = 0\n",
					"DateLoopCounter = 0\n",
					""
				],
				"execution_count": 224
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"manual_date=\"2022-11-13\"\r\n",
					"manual=1\r\n",
					"current_date=0\r\n",
					"loop_dates=0"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"if manual==1 and current_date==0 and loop_dates==0:\r\n",
					"    DateList=[]\r\n",
					"    DateList.append(manual_date)\r\n",
					"elif current_date==1 and manual_date==0 and loop_dates==0:\r\n",
					"    DateList=[]\r\n",
					"    DateList.append(str(today_date))\r\n",
					"elif current_date==0 and manual_date==0 and loop_dates==1:\r\n",
					"    DateList=DateList\r\n",
					"\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"for i in DateList:\r\n",
					"    df2=pd.DataFrame()\r\n",
					"    for k in pathtoreadcsv:\r\n",
					"        location1 = k  \r\n",
					"        location1= location1+ str(i).split(\"-\")[0]+\"/\"+str(i).split(\"-\")[1]+\"/\"+str(i).split(\"-\")[2]+\"/\"+str(\"*\")\r\n",
					"        print(location1)\r\n",
					"        #df = pd.read_parquet(location1)\r\n",
					"            #df2=  spark.read.load(\"abfss://phelanrealtime@ayanadatalake.dfs.core.windows.net/phelan_realtime/2022/04/08/*\", format='csv', header=True)\r\n",
					"        df2_a = spark.read.load(location1, format='csv', header=True)\r\n",
					"        #display(df)\r\n",
					"        df2_a=df2_a.toPandas()\r\n",
					"        df2_a\r\n",
					"        df2_a['timestamp']=df2_a[\"timestamp\"].apply(lambda x:x.split(\"+\")[0])\r\n",
					"\r\n",
					"        df2=df2.append(df2_a)\r\n",
					"\r\n",
					"    df2.shape"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"location1 = pattoreadcsv_a  \n",
					"location1= location1+ str(DateList[DateLoopCounter]).split(\"-\")[0]+\"/\"+str(DateList[DateLoopCounter]).split(\"-\")[1]+\"/\"+str(DateList[DateLoopCounter]).split(\"-\")[2]+\"/\"+str(\"*\")\n",
					"print(location1)\n",
					"#df = pd.read_parquet(location1)"
				],
				"execution_count": 226
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#df2=  spark.read.load(\"abfss://phelanrealtime@ayanadatalake.dfs.core.windows.net/phelan_realtime/2022/04/08/*\", format='csv', header=True)\n",
					"df2_a = spark.read.load(location1, format='csv', header=True)\n",
					"#display(df)\n",
					"df2_a=df2_a.toPandas()\n",
					"df2_a"
				],
				"execution_count": 227
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df2_a['timestamp']=df2_a[\"timestamp\"].apply(lambda x:x.split(\"+\")[0])"
				],
				"execution_count": 228
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df2=pd.DataFrame()\n",
					"df2=df2.append(df2_a)\n",
					"#df2=df2.append(df2_b)\n",
					"#df2=df2.append(df2_c)\n",
					"#df2=df2.append(df2_d)\n",
					"#df2=df2.append(df2_a2)\n",
					"#df2=df2.append(df2_b2)\n",
					"#df2=df2.append(df2_c2)\n",
					"#df2=df2.append(df2_d2)\n",
					"\n",
					"df2.shape"
				],
				"execution_count": 229
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_raw=df2.copy()"
				],
				"execution_count": 230
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#StaticFile = 'abfss://nucleus@ayanadatalake.dfs.core.windows.net/Bkn_StaticFiles/AxonBkn_PVSyst.xlsx'\n",
					"daily_df=pd.read_excel(Static_file_PV_Syst_location)\n",
					"#daily_df.head()\n",
					"daily_df.head()"
				],
				"execution_count": 231
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#StaticFile = 'abfss://nucleus@ayanadatalake.dfs.core.windows.net/Bkn_StaticFiles/AxonBkn_PVSyst.xlsx'\n",
					"daily_df=pd.read_excel(Static_file_PV_Syst_location)\n",
					"#daily_df.head()\n",
					"daily_df.head()\n",
					"Pr=daily_df[daily_df[\"Date\"]==str(DateList[DateLoopCounter])]\n",
					"Pr=(Pr.iloc[0,5]/Pr.iloc[0,4])/463.31\n",
					"Pr"
				],
				"execution_count": 232
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_Static=pd.read_excel(Static_file_loss_Calculation)\n",
					"df_Static.head(5)\n",
					"df_Static[\"SimilarTag\"]=df_Static[\"SimilarTag\"]\n",
					"df_Static"
				],
				"execution_count": 233
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_Static"
				],
				"execution_count": 234
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Dc_load=float(df_Static[df_Static[\"SimilarTag\"]==\"ICR1..INV2.TODAY_GEN\"][\"InvDCLoad\"].iloc[0])\n",
					"Dc_load"
				],
				"execution_count": 235
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_tag=pd.read_excel('abfss://devlop@ayanadatalake.dfs.core.windows.net/Bikaner/Bkn_Tables.xlsx',sheet_name=\"Table2\")\n",
					"df_tag"
				],
				"execution_count": 236
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Inverter_allEnergyTags=df_tag['InvEnergy_kWh'].to_list()\n",
					"len(Inverter_allEnergyTags)"
				],
				"execution_count": 237
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_raw.sort_values(by=\"timestamp\",ascending=True,inplace=True)\n",
					"#df.sort_values(by=\"timestamp\",ascending=True,inplace=True)\n",
					"df_raw.drop([\"deviceid\",\"quality\",\"ISTtime\",\"EventProcessedUtcTime\",\"PartitionId\",\"EventEnqueuedUtcTime\",\"IoTHub\"],axis=1,inplace=True)\n",
					"df_raw[\"timestamp\"]=df_raw[\"timestamp\"].astype(\"datetime64[ns]\")\n",
					"df_raw[\"Date\"]=pd.DatetimeIndex(df_raw[\"timestamp\"]).date\n",
					"df_raw[\"Time\"]=pd.DatetimeIndex(df_raw[\"timestamp\"]).time\n",
					"df_raw[\"Hour\"]=pd.DatetimeIndex(df_raw[\"timestamp\"]).hour\n",
					"df_raw[\"Minute\"]=pd.DatetimeIndex(df_raw[\"timestamp\"]).minute\n",
					"df_raw.rename(columns={\"timestamp\":\"ISTtime\"},inplace=True)\n",
					"df_raw=df_raw[[\"ISTtime\",\"itemname\",\"value\",\"Date\",\"Time\",\"Hour\",\"Minute\"]]\n",
					"df_raw[\"value\"]=df_raw[\"value\"].astype(\"float64\")\n",
					"df_raw[\"SPP\"]=\"Bikaner\"\n",
					""
				],
				"execution_count": 238
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Radiation_Block1=df2[df2['itemname']==\"ICR1.WMS_PRG.WMS.GLOBAL_TILT_IRRADIATION_Wm2\"] # \n",
					"Radiation_Block1=Radiation_Block1[[\"ISTtime\",\"itemname\",\"value\"]]\n",
					"Radiation_Block1[\"ISTtime\"]=Radiation_Block1[\"ISTtime\"].astype(\"datetime64[ns]\")\n",
					"Radiation_Block1[\"Hour\"]=pd.DatetimeIndex(Radiation_Block1[\"ISTtime\"]).hour\n",
					"Radiation_Block1[\"Minute\"]=pd.DatetimeIndex(Radiation_Block1[\"ISTtime\"]).minute\n",
					"\n",
					"Radiation_Block5=df2[df2['itemname']==\"ICR5.WMS_PRG.WMS.GLOBAL_TILT_IRRADIATION_Wm2\"]\n",
					"Radiation_Block5=Radiation_Block5[[\"ISTtime\",\"itemname\",\"value\"]]\n",
					"Radiation_Block5[\"ISTtime\"]=Radiation_Block5[\"ISTtime\"].astype(\"datetime64[ns]\")\n",
					"Radiation_Block5[\"Hour\"]=pd.DatetimeIndex(Radiation_Block5[\"ISTtime\"]).hour\n",
					"Radiation_Block5[\"Minute\"]=pd.DatetimeIndex(Radiation_Block5[\"ISTtime\"]).minute\n",
					"\n",
					"Radiation_Block18=df2[df2['itemname']==\"ICR18.WMS_PRG.WMS.GLOBAL_TILT_IRRADIATION_Wm2\"]\n",
					"Radiation_Block18=Radiation_Block18[[\"ISTtime\",\"itemname\",\"value\"]]\n",
					"Radiation_Block18[\"ISTtime\"]=Radiation_Block18[\"ISTtime\"].astype(\"datetime64[ns]\")\n",
					"Radiation_Block18[\"Hour\"]=pd.DatetimeIndex(Radiation_Block18[\"ISTtime\"]).hour\n",
					"Radiation_Block18[\"Minute\"]=pd.DatetimeIndex(Radiation_Block18[\"ISTtime\"]).minute\n",
					"\n",
					"Radiation_Block23=df2[df2['itemname']==\"ICR23.WMS_PRG.WMS.GLOBAL_TILT_IRRADIATION_Wm2\"]\n",
					"#Radiation_Block4=df2[df2['itemname']==\"MCR..MCR_WMS.GTI_W\"]\n",
					"Radiation_Block23=Radiation_Block23[[\"ISTtime\",\"itemname\",\"value\"]]\n",
					"Radiation_Block23[\"ISTtime\"]=Radiation_Block23[\"ISTtime\"].astype(\"datetime64[ns]\")\n",
					"Radiation_Block23[\"Hour\"]=pd.DatetimeIndex(Radiation_Block23[\"ISTtime\"]).hour\n",
					"Radiation_Block23[\"Minute\"]=pd.DatetimeIndex(Radiation_Block23[\"ISTtime\"]).minute\n",
					"Radiation_Block23\n",
					"\n",
					"Radiation_Block12=df2[df2['itemname']==\"MCR1..GLOBAL_TILT_IRRADIATION_Wm2\"]\n",
					"Radiation_Block12=Radiation_Block12[[\"ISTtime\",\"itemname\",\"value\"]]\n",
					"Radiation_Block12[\"ISTtime\"]=Radiation_Block12[\"ISTtime\"].astype(\"datetime64[ns]\")\n",
					"Radiation_Block12[\"Hour\"]=pd.DatetimeIndex(Radiation_Block12[\"ISTtime\"]).hour\n",
					"Radiation_Block12[\"Minute\"]=pd.DatetimeIndex(Radiation_Block12[\"ISTtime\"]).minute\n",
					""
				],
				"execution_count": 239
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Block1_list=['ICR1..INV1.kW',\n",
					"'ICR1..INV2.kW',\n",
					"'ICR1..INV3.kW',\n",
					"'ICR1..INV4.kW',\n",
					"'ICR3..INV1.kW',\n",
					"'ICR3..INV2.kW',\n",
					"'ICR3..INV3.kW',\n",
					"'ICR3..INV4.kW',]\n",
					"Block2_list=['ICR2..INV3.kW',\n",
					"'ICR2..INV2.kW',\n",
					"'ICR2..INV1.kW',\n",
					"'ICR2..INV4.kW',\n",
					"'ICR4..INV1.kW',\n",
					"'ICR4..INV3.kW',\n",
					"'ICR4..INV4.kW',\n",
					"'ICR4..INV2.kW',]\n",
					"Block3_list=['ICR13..INV2.kW',\n",
					"'ICR13..INV1.kW',\n",
					"'ICR13..INV3.kW',\n",
					"'ICR13..INV4.kW',\n",
					"'ICR8..INV4.kW',\n",
					"'ICR8..INV3.kW',\n",
					"'ICR8..INV2.kW',\n",
					"'ICR8..INV1.kW',]\n",
					"\n",
					"Block4_list=['ICR16..INV4.kW',\n",
					"'ICR16..INV3.kW',\n",
					"'ICR16..INV2.kW',\n",
					"'ICR16..INV1.kW',\n",
					"'ICR15..INV4.kW',\n",
					"'ICR15..INV3.kW',\n",
					"'ICR15..INV2.kW',\n",
					"'ICR15..INV1.kW',]\n",
					"\n",
					"Block5_list=['ICR17..INV1.kW',\n",
					"'ICR17..INV2.kW',\n",
					"'ICR17..INV3.kW',\n",
					"'ICR17..INV4.kW',\n",
					"'ICR18..INV1.kW',\n",
					"'ICR18..INV2.kW',\n",
					"'ICR18..INV3.kW',\n",
					"'ICR18..INV4.kW',]\n",
					"Block6_list=['ICR10..INV3.kW',\n",
					"'ICR10..INV2.kW',\n",
					"'ICR10..INV1.kW',\n",
					"'ICR10..INV4.kW',\n",
					"'ICR9..INV1.kW',\n",
					"'ICR9..INV3.kW',\n",
					"'ICR9..INV4.kW',\n",
					"'ICR9..INV2.kW',]\n",
					"Block7_list=['ICR11..INV2.kW',\n",
					"'ICR11..INV1.kW',\n",
					"'ICR11..INV3.kW',\n",
					"'ICR11..INV4.kW',\n",
					"'ICR7..INV4.kW',\n",
					"'ICR7..INV3.kW',\n",
					"'ICR7..INV2.kW',\n",
					"'ICR7..INV1.kW',]\n",
					"\n",
					"Block8_list=['ICR12..INV4.kW',\n",
					"'ICR12..INV3.kW',\n",
					"'ICR12..INV2.kW',\n",
					"'ICR12..INV1.kW',\n",
					"'ICR12..INV4.kW',\n",
					"'ICR6..INV3.kW',\n",
					"'ICR6..INV2.kW',\n",
					"'ICR6..INV1.kW',]\n",
					"\n",
					"Block9_list=['ICR14..INV1.kW',\n",
					"'ICR14..INV2.kW',\n",
					"'ICR14..INV3.kW',\n",
					"'ICR14..INV4.kW',\n",
					"'ICR5..INV1.kW',\n",
					"'ICR5..INV2.kW',\n",
					"'ICR5..INV3.kW',\n",
					"'ICR5..INV4.kW',]\n",
					"Block10_list=['ICR19..INV3.kW',\n",
					"'ICR19..INV2.kW',\n",
					"'ICR19..INV1.kW',\n",
					"'ICR19..INV4.kW',\n",
					"'ICR20..INV1.kW',\n",
					"'ICR20..INV3.kW',\n",
					"'ICR20..INV4.kW',\n",
					"'ICR20..INV2.kW',]\n",
					"Block11_list=['ICR21..INV2.kW',\n",
					"'ICR21..INV1.kW',\n",
					"'ICR21..INV3.kW',\n",
					"'ICR21..INV4.kW',\n",
					"'ICR23..INV4.kW',\n",
					"'ICR23..INV3.kW',\n",
					"'ICR23..INV2.kW',\n",
					"'ICR23..INV1.kW',]\n",
					"\n",
					"Block12_list=['ICR22..INV4.kW',\n",
					"'ICR22..INV3.kW',\n",
					"'ICR22..INV2.kW',\n",
					"'ICR22..INV1.kW',\n",
					"'ICR24..INV4.kW',\n",
					"'ICR24..INV3.kW',\n",
					"'ICR24..INV2.kW',\n",
					"'ICR24..INV1.kW',]\n",
					"\n",
					"print(len(Block1_list),len(Block2_list),len(Block3_list),len(Block4_list),len(Block5_list))\n",
					"\n",
					"print(len(Block6_list),len(Block7_list),len(Block8_list),len(Block8_list),len(Block9_list))\n",
					"\n",
					"print(len(Block11_list),len(Block12_list))\n",
					"\n",
					""
				],
				"execution_count": 240
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#data_frame_list_final=[]\r\n",
					"#data_frame_inverter_downtime_list_final=[]"
				],
				"execution_count": 241
			},
			{
				"cell_type": "code",
				"source": [
					"#data_frame_list_final=[]\n",
					"#data_frame_inverter_downtime_list_final=[]\n",
					"def inverter_downtime_logic(Block_list,Radiation_Tag,missing_inverters_tags,df,df1,df2):\n",
					"    \n",
					"    \n",
					"    import datetime\n",
					"    print(Block_list)\n",
					"    data_frame_list=[]\n",
					"    data_frame_inverter_downtime_list=[]\n",
					"    for i in Block_list:\n",
					"        if i in missing_inverters_tags:\n",
					"            continue\n",
					"        else:\n",
					"            each_tag_list=[]\n",
					"            each_tag_list.append(i)\n",
					"            df_each_tag=df2[df2[\"itemname\"]==i]\n",
					"            df_each_tag_with_radiation=pd.merge(df_each_tag,Radiation_Tag,how=\"inner\",left_on=[\"Hour\",\"Minute\"],right_on=[\"Hour\",\"Minute\"])\n",
					"            df_each_tag_with_radiation=df_each_tag_with_radiation.drop_duplicates(subset=[\"Hour\",\"Minute\"]).reset_index(drop=True)\n",
					"            df_each_tag_with_radiation=df_each_tag_with_radiation[[\"ISTtime_x\",\"itemname_x\",\"value_x\",\"value_y\"]]\n",
					"            df_each_tag_with_radiation[\"value_y\"]=df_each_tag_with_radiation[\"value_y\"].astype(\"float64\")\n",
					"            df_each_tag_with_radiation_pattern=df_each_tag_with_radiation[(df_each_tag_with_radiation[\"value_x\"]==0) & (df_each_tag_with_radiation[\"value_y\"]!=0)].reset_index(drop=True)\n",
					"            \n",
					"            print(df_each_tag_with_radiation)       \n",
					"            up_time=str(df_each_tag_with_radiation[df_each_tag_with_radiation[\"value_x\"]!=0][\"ISTtime_x\"].head(1)).split(\" \")[4].split(\"\\n\")[0]\n",
					"            sleep_time=str(df_each_tag_with_radiation[df_each_tag_with_radiation[\"value_x\"]!=0][\"ISTtime_x\"].tail(1)).split(\" \")[4].split(\"\\n\")[0]\n",
					"            Dc_load_Tag=i.split(\"..\")[0]+\"..\"+i.split(\"..\")[1].split(\".\")[0]+\".\"+\"TODAY_GEN\"\n",
					"            print(Dc_load_Tag)\n",
					"            Dc_load=float(df_Static[df_Static[\"SimilarTag\"]==Dc_load_Tag][\"InvDCLoad\"].iloc[0])\n",
					"            print(Dc_load)\n",
					"            up_time_hour=up_time.split(\":\")[0]\n",
					"            up_time_minute=up_time.split(\":\")[1]\n",
					"            up_time_second=up_time.split(\":\")[2].split(\".\")[0]\n",
					"            #up_time_millisecond=up_time.split(\":\")[2].split(\".\")[1]\n",
					"            sleep_time_hour=sleep_time.split(\":\")[0]\n",
					"            sleep_time_minute=sleep_time.split(\":\")[1]\n",
					"            sleep_time_second=sleep_time.split(\":\")[2].split(\".\")[0]\n",
					"            #sleep_time_millisecond=sleep_time.split(\":\")[2].split(\".\")[1]\n",
					"            a1=datetime.timedelta(hours=int(up_time_hour), minutes=int(up_time_minute), seconds=int(up_time_second)) \n",
					"            b1=datetime.timedelta(hours=int(sleep_time_hour), minutes=int(sleep_time_minute), seconds=int(sleep_time_second))\n",
					"            op_minute=(b1-a1).seconds/60\n",
					"            df_each_tag_inv_efficiency_average=df1[(df1[\"itemname\"]==i.split(\".\")[0]+\"..\"+i.split(\".\")[2]+\".INVERTER_EFFICIENCY\") & (df1[\"value\"]!=0)][\"value\"].mean()\n",
					"            df_each_tag_inv_efficiency_max=df1[(df1[\"itemname\"]==i.split(\".\")[0]+\"..\"+i.split(\".\")[2]+\".INVERTER_EFFICIENCY\") & (df1[\"value\"]!=0)][\"value\"].max()\n",
					"\n",
					"            #print(up_time,sleep_time)\n",
					"            downtime=0\n",
					"            energy_loss=0\n",
					"            if len(df_each_tag_with_radiation_pattern)==0:\n",
					"                each_tag_list.append(np.round(downtime,2))\n",
					"                each_tag_list.append(up_time)\n",
					"                each_tag_list.append(sleep_time)\n",
					"                each_tag_list.append(op_minute)\n",
					"                each_tag_list.append(op_minute-np.round(downtime,2))\n",
					"                each_tag_list.append(np.round(df_each_tag_inv_efficiency_average,4))\n",
					"                each_tag_list.append(np.round(df_each_tag_inv_efficiency_max,4))\n",
					"                each_tag_list.append(np.round((energy_loss/60000)*df_each_tag_inv_efficiency_max*downtime,2))\n",
					"                data_frame_list.append(each_tag_list) \n",
					"            else:\n",
					"                print(df_each_tag_with_radiation_pattern)\n",
					"                #energy_loss=list(df_each_tag_with_radiation_pattern[\"value_y\"])\n",
					"                #energy_loss=[i if i<890 else 890 for i in energy_loss]\n",
					"                #energy_loss=np.sum(energy_loss)\n",
					"                index_list=[-1]\n",
					"                for i in range(0,len(df_each_tag_with_radiation_pattern)):\n",
					"                    if i<=len(df_each_tag_with_radiation_pattern)-2:\n",
					"                        #print(\"i=\",i)\n",
					"                        hour_i=int(str(df_each_tag_with_radiation_pattern.iloc[i,0]).split(' ')[1].split(\":\")[0])\n",
					"                        minute_i=int(str(df_each_tag_with_radiation_pattern.iloc[i,0]).split(' ')[1].split(\":\")[1])\n",
					"                        second_i=int(str(df_each_tag_with_radiation_pattern.iloc[i,0]).split(' ')[1].split(\":\")[2].split(\".\")[0])\n",
					"                        #millisecond_i=int(str(df_each_tag_with_radiation_pattern.iloc[i,0]).split(' ')[1].split(\":\")[2].split(\".\")[1])\n",
					"                        hour_ii=int(str(df_each_tag_with_radiation_pattern.iloc[i+1,0]).split(' ')[1].split(\":\")[0])\n",
					"                        minute_ii=int(str(df_each_tag_with_radiation_pattern.iloc[i+1,0]).split(' ')[1].split(\":\")[1])\n",
					"                        second_ii=int(str(df_each_tag_with_radiation_pattern.iloc[i+1,0]).split(' ')[1].split(\":\")[2].split(\".\")[0])\n",
					"                        #millisecond_ii=int(str(df_each_tag_with_radiation_pattern.iloc[i+1,0]).split(' ')[1].split(\":\")[2].split(\".\")[1])\n",
					"                        a=datetime.timedelta(hours=int(hour_i), minutes=int(minute_i), seconds=int(second_i)) \n",
					"                        b=datetime.timedelta(hours=int(hour_ii), minutes=int(minute_ii), seconds=int(second_ii))\n",
					"                        minute=(b-a).seconds/60\n",
					"                        #print(minute)\n",
					"                        if minute>12:\n",
					"                            index_list.append(i)\n",
					"                    else:\n",
					"                        break\n",
					"                index_list.append(len(df_each_tag_with_radiation_pattern)-1)\n",
					"                downtime=0\n",
					"                energy_loss=0\n",
					"                print(index_list)\n",
					"                for o in range(len(index_list)):\n",
					"                    if o<=(len(index_list)-2):\n",
					"                        To=str(df_each_tag_with_radiation_pattern.iloc[index_list[o]+1,0]).split(' ')[1]\n",
					"                        From=str(df_each_tag_with_radiation_pattern.iloc[index_list[o+1],0]).split(' ')[1]\n",
					"                        print(To,From)\n",
					"                        Energy_Tag=(df_each_tag_with_radiation_pattern.iloc[0,1].split(\"..\")[0])+\"..\"+(df_each_tag_with_radiation_pattern.iloc[0,1].split(\"..\")[1]).split(\".\")[0]+\".\"+\"TODAY_GEN\"\n",
					"                        print(\"Energy_Tag_is\",Energy_Tag)\n",
					"                        #deviation\n",
					"                        To=str(df.iloc[0,0]).split(\" \")[0]+\" \"+To\n",
					"                        From=str(df.iloc[0,0]).split(\" \")[0]+\" \"+From\n",
					"                        deviation=df[(df[\"itemname\"]==Energy_Tag) & (df[\"ISTtime\"]>=str(To)) & (df[\"ISTtime\"]<=str(From))   ][\"value\"].std()\n",
					"                        print(\"deviation is\",deviation)\n",
					"                        energy_start=df[(df[\"itemname\"]==Energy_Tag) & (df[\"ISTtime\"]>=str(To)) & (df[\"ISTtime\"]<=str(From))   ].head(1)[\"value\"].iloc[0]\n",
					"                        print(\"deviation is\",deviation)\n",
					"                        energy_final=df[(df[\"itemname\"]==Energy_Tag) & (df[\"ISTtime\"]>=str(To)) & (df[\"ISTtime\"]<=str(From))   ].tail(1)[\"value\"].iloc[0]\n",
					"                        if ((energy_final-energy_start)<10) & (energy_start!=0):\n",
					"                            \n",
					"                            print(\"inside if\")\n",
					"                            ml2=[]\n",
					"                            ml2.append(str(df_each_tag_with_radiation_pattern.iloc[0,0]).split(' ')[0])\n",
					"                            ml2.append(df_each_tag_with_radiation_pattern.iloc[0,1])\n",
					"                            #To=str(df_each_tag_with_radiation_pattern.iloc[index_list[i]+1,0]).split(' ')[1]\n",
					"                            #From=str(df_each_tag_with_radiation_pattern.iloc[index_list[i+1],0]).split(' ')[1]\n",
					"\n",
					"                            ml2.append(str(df_each_tag_with_radiation_pattern.iloc[index_list[o]+1,0]).split(' ')[1])\n",
					"                            ml2.append(str(df_each_tag_with_radiation_pattern.iloc[index_list[o+1],0]).split(' ')[1])\n",
					"\n",
					"                            hour_i=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[o]+1,0]).split(' ')[1].split(\":\")[0])\n",
					"                            minute_i=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[o]+1,0]).split(' ')[1].split(\":\")[1])\n",
					"                            second_i=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[o]+1,0]).split(' ')[1].split(\":\")[2].split(\".\")[0])\n",
					"                            #millisecond_i=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[i]+1,0]).split(' ')[1].split(\":\")[2].split(\".\")[1])\n",
					"                            hour_ii=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[o+1],0]).split(' ')[1].split(\":\")[0])\n",
					"                            minute_ii=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[o+1],0]).split(' ')[1].split(\":\")[1])\n",
					"                            second_ii=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[o+1],0]).split(' ')[1].split(\":\")[2].split(\".\")[0])\n",
					"                            #millisecond_ii=int(str(df_each_tag_with_radiation_pattern.iloc[index_list[i+1],0]).split(' ')[1].split(\":\")[2].split(\".\")[1])\n",
					"                            a=datetime.timedelta(hours=int(hour_i), minutes=int(minute_i), seconds=int(second_i)) \n",
					"                            b=datetime.timedelta(hours=int(hour_ii), minutes=int(minute_ii), seconds=int(second_ii))\n",
					"                            #print(hour_i,minute_i,second_i,hour_ii,minute_ii,second_ii)\n",
					"                            minute=(b-a).seconds/60\n",
					"                            downtime=downtime+minute\n",
					"                            energy_sum_during_downtime=Radiation_Block1[(Radiation_Block1[\"ISTtime\"]>=str(To)) & (Radiation_Block1[\"ISTtime\"]<=str(From))   ][\"value\"].sum()\n",
					"                            energy_loss=energy_loss+energy_sum_during_downtime\n",
					"                            ml2.append(minute)\n",
					"                            data_frame_inverter_downtime_list.extend([ml2])\n",
					"                print(energy_loss,Pr,Dc_load)\n",
					"                each_tag_list.append(np.round(downtime,2))\n",
					"                each_tag_list.append(up_time)\n",
					"                each_tag_list.append(sleep_time)\n",
					"                each_tag_list.append(op_minute)\n",
					"                each_tag_list.append(op_minute-np.round(downtime,2))\n",
					"                each_tag_list.append(np.round(df_each_tag_inv_efficiency_average,4))\n",
					"                each_tag_list.append(np.round(df_each_tag_inv_efficiency_max,4))\n",
					"                each_tag_list.append(np.round((energy_loss/12000)*(df_each_tag_inv_efficiency_max/100)*Pr*Dc_load,2))\n",
					"                data_frame_list.append(each_tag_list)\n",
					"    data_frame_list_final.extend(data_frame_list)\n",
					"    data_frame_inverter_downtime_list_final.extend(data_frame_inverter_downtime_list)\n",
					"\n",
					"    return data_frame_list_final"
				],
				"execution_count": 242
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"time_batch_list_interval=[(6,8),(9,10),(11,12),(13,14),(15,16),(17,18)]"
				],
				"execution_count": 243
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#time_batch_list=[(6,8),(8,10),(10,12),(12,14),(14,16),(16,19)]\n",
					"def time_batch_list(Batch_Start,Batch_finish):\n",
					"    \n",
					"    df=df_raw[(df_raw[\"Hour\"]>=Batch_Start) & (df_raw[\"Hour\"]<=Batch_finish)]\n",
					"    df1=df.copy()\n",
					"    df2=df.copy()\n",
					"    df_preprocessed=df.copy()\n",
					"    df=df[df['itemname'].isin(Inverter_allEnergyTags)]\n",
					"    len(df[\"itemname\"].unique())\n",
					"    df[\"itemname\"]=df[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:x[0])+\"..INV\"+df[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:str(x[-1].split(\"_\")[0])[-1])+\".\"+\"TODAY_GEN\"\n",
					"    new_columns_list=df_tag.columns[[9,10,12,13,15,16,17,18,19,20,21,22,26,27,29,28,30,31,32,33]]\n",
					"    len(new_columns_list)\n",
					"    tagname=new_columns_list[0]\n",
					"    Tags=df_tag[str(tagname)].to_list()\n",
					"    print(len(Tags))\n",
					"    df_preprocess_new_columns=df_preprocessed[df_preprocessed['itemname'].isin(Tags)]\n",
					"    print(new_columns_list[0])\n",
					"    print(len(df_preprocess_new_columns[\"itemname\"].unique()))\n",
					"    df_preprocess_new_columns[\"itemname\"]=df_preprocess_new_columns[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:x[0])+\"..INV\"+df_preprocess_new_columns[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:str(x[2].split(\"_\")[0])[-1])+\".\"+\"TODAY_GEN\"\n",
					"    df_preprocess_new_columns[\"ICR\"]=df_preprocess_new_columns[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"    df_preprocess_new_columns[\"INV\"]=df_preprocess_new_columns[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"    ICR_dict={\"ICR1\":\"ICR01\",\n",
					"            \"ICR2\":\"ICR02\",\n",
					"            \"ICR3\":\"ICR03\",\n",
					"            \"ICR4\":\"ICR04\",\n",
					"            \"ICR5\":\"ICR05\",\n",
					"            \"ICR6\":\"ICR06\",\n",
					"            \"ICR7\":\"ICR07\",\n",
					"            \"ICR8\":\"ICR08\",\n",
					"            \"ICR9\":\"ICR09\"}\n",
					"    df_preprocess_new_columns[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"    #print(\"Unique_Inv\",len(df_preprocess_new_columns[\"INV\"].unique()))\n",
					"\n",
					"    df_preprocess_new_columns[\"Inv\"]=df_preprocess_new_columns[\"ICR\"].str[0]+df_preprocess_new_columns[\"ICR\"].str[-2:]+\"_\"+df_preprocess_new_columns[\"INV\"].str[-1]\n",
					"    df_preprocess_new_columns=df_preprocess_new_columns.groupby(by=[\"Inv\"]).agg(\"max\").reset_index()\n",
					"    print(\"Unique_Inv\",len(df_preprocess_new_columns[\"Inv\"].unique()))\n",
					"    print(df_preprocess_new_columns)\n",
					"    df_preprocess_new_columns=df_preprocess_new_columns[[\"Inv\",\"value\"]]\n",
					"    df_final_new_columns=df_preprocess_new_columns\n",
					"    df_final_new_columns.to_excel(\"abfss://devlop@ayanadatalake.dfs.core.windows.net/Bikaner/Bkn_example3.xlsx\")\n",
					"\n",
					"\n",
					"    for i in range(1,19):\n",
					"        tagname=new_columns_list[i]\n",
					"        Tags=df_tag[str(tagname)].to_list()\n",
					"        #print(len(Tags))\n",
					"        df_preprocess_new_columns=df_preprocessed[df_preprocessed['itemname'].isin(Tags)]\n",
					"        print(new_columns_list[i])\n",
					"        print(len(df_preprocess_new_columns[\"itemname\"].unique()))\n",
					"        df_preprocess_new_columns[\"itemname\"]=df_preprocess_new_columns[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:x[0])+\"..INV\"+df_preprocess_new_columns[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:str(x[2].split(\"_\")[0])[-1])+\".\"+\"TODAY_GEN\"\n",
					"        df_preprocess_new_columns[\"ICR\"]=df_preprocess_new_columns[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"        df_preprocess_new_columns[\"INV\"]=df_preprocess_new_columns[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"        print(df_preprocess_new_columns)\n",
					"        ICR_dict={\"ICR1\":\"ICR01\",\n",
					"             \"ICR2\":\"ICR02\",\n",
					"             \"ICR3\":\"ICR03\",\n",
					"             \"ICR4\":\"ICR04\",\n",
					"             \"ICR5\":\"ICR05\",\n",
					"             \"ICR6\":\"ICR06\",\n",
					"             \"ICR7\":\"ICR07\",\n",
					"             \"ICR8\":\"ICR08\",\n",
					"             \"ICR9\":\"ICR09\"}\n",
					"        df_preprocess_new_columns[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"\n",
					"        df_preprocess_new_columns[\"Inv\"]=df_preprocess_new_columns[\"ICR\"].str[0]+df_preprocess_new_columns[\"ICR\"].str[-2:]+\"_\"+df_preprocess_new_columns[\"INV\"].str[-1]\n",
					"        df_preprocess_new_columns=df_preprocess_new_columns.groupby(by=[\"Inv\"]).agg(\"max\").reset_index()\n",
					"        df_preprocess_new_columns=df_preprocess_new_columns[[\"Inv\",\"value\"]]\n",
					"        print(len(df_preprocess_new_columns))\n",
					"        df_final_new_columns=pd.merge(df_final_new_columns,df_preprocess_new_columns,on=\"Inv\")    \n",
					"\n",
					"\n",
					"    df_final_new_columns\n",
					"\n",
					"    df_final_new_columns1=df_final_new_columns.copy()\n",
					"\n",
					"    tagname=new_columns_list[19]\n",
					"    Tags=df_tag[str(tagname)].to_list()\n",
					"    print(len(Tags))\n",
					"    df_preprocess_new_columns=df_preprocessed[df_preprocessed['itemname'].isin(Tags)]\n",
					"    print(new_columns_list[19])\n",
					"    print(len(df_preprocess_new_columns[\"itemname\"].unique()))\n",
					"    df_preprocess_new_columns[\"itemname\"]=df_preprocess_new_columns[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:x[0])+\"..INV\"+df_preprocess_new_columns[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:str(x[4].split(\"_\")[1])[-1])+\".\"+\"TODAY_GEN\"\n",
					"    df_preprocess_new_columns[\"ICR\"]=df_preprocess_new_columns[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"    df_preprocess_new_columns[\"INV\"]=df_preprocess_new_columns[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"    ICR_dict={\"ICR1\":\"ICR01\",\n",
					"            \"ICR2\":\"ICR02\",\n",
					"            \"ICR3\":\"ICR03\",\n",
					"            \"ICR4\":\"ICR04\",\n",
					"            \"ICR5\":\"ICR05\",\n",
					"            \"ICR6\":\"ICR06\",\n",
					"            \"ICR7\":\"ICR07\",\n",
					"            \"ICR8\":\"ICR08\",\n",
					"            \"ICR9\":\"ICR09\"}\n",
					"    df_preprocess_new_columns[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"    #print(\"Unique_Inv\",len(df_preprocess_new_columns[\"INV\"].unique()))\n",
					"\n",
					"    df_preprocess_new_columns[\"Inv\"]=df_preprocess_new_columns[\"ICR\"].str[0]+df_preprocess_new_columns[\"ICR\"].str[-2:]+\"_\"+df_preprocess_new_columns[\"INV\"].str[-1]\n",
					"    df_preprocess_new_columns=df_preprocess_new_columns.groupby(by=[\"Inv\"]).agg(\"max\").reset_index()\n",
					"    print(\"Unique_Inv\",len(df_preprocess_new_columns[\"Inv\"].unique()))\n",
					"    print(df_preprocess_new_columns)\n",
					"    df_preprocess_new_columns=df_preprocess_new_columns[[\"Inv\",\"value\"]]\n",
					"    df_final_new_columns2=pd.merge(df_final_new_columns1,df_preprocess_new_columns,on=\"Inv\")\n",
					"    df_final_new_columns.to_excel(\"abfss://devlop@ayanadatalake.dfs.core.windows.net/Bikaner/Bkn_example3.xlsx\")\n",
					"\n",
					"\n",
					"    new_columns_list=new_columns_list.insert(0,\"Inv\")\n",
					"\n",
					"    df_final_new_columns2=pd.DataFrame(df_final_new_columns2.values,columns=new_columns_list)\n",
					"    df[\"ICR\"]=df[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"    df[\"INV\"]=df[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"\n",
					"    Blocklist=[]\n",
					"    for i in range(len(df)):\n",
					"        if df.iloc[i,1].split(\"..\")[0] in [\"ICR1\",\"ICR3\"]:\n",
					"            Blocklist.append(\"Bkn01\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR2\",\"ICR4\"]:\n",
					"            Blocklist.append(\"Bkn02\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR13\",\"ICR8\"]:\n",
					"            Blocklist.append(\"Bkn03\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR15\",\"ICR16\"]:\n",
					"            Blocklist.append(\"Bkn04\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR17\",\"ICR18\"]:\n",
					"            Blocklist.append(\"Bkn05\")\n",
					"\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR10\",\"ICR9\"]:\n",
					"            Blocklist.append(\"Bkn06\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR11\",\"ICR7\"]:\n",
					"            Blocklist.append(\"Bkn07\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR12\",\"ICR6\"]:\n",
					"            Blocklist.append(\"Bkn08\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR14\",\"ICR5\"]:\n",
					"            Blocklist.append(\"Bkn09\")\n",
					"\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR19\",\"ICR20\"]:\n",
					"            Blocklist.append(\"Bkn10\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR21\",\"ICR23\"]:\n",
					"            Blocklist.append(\"Bkn11\")\n",
					"        elif df.iloc[i,1].split(\"..\")[0] in [\"ICR22\",\"ICR24\"]:\n",
					"            Blocklist.append(\"Bkn12\")\n",
					"\n",
					"\n",
					"\n",
					"    df[\"Block\"]=Blocklist\n",
					"\n",
					"    df[\"Inverter_OEM\"]=\"SG3125HV-20\"\n",
					"    ICR_dict={\"ICR1\":\"ICR01\",\n",
					"             \"ICR2\":\"ICR02\",\n",
					"             \"ICR3\":\"ICR03\",\n",
					"             \"ICR4\":\"ICR04\",\n",
					"             \"ICR5\":\"ICR05\",\n",
					"             \"ICR6\":\"ICR06\",\n",
					"             \"ICR7\":\"ICR07\",\n",
					"             \"ICR8\":\"ICR08\",\n",
					"             \"ICR9\":\"ICR09\"}\n",
					"    df[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"\n",
					"    df[\"Inv\"]=df[\"ICR\"].str[0]+df[\"ICR\"].str[-2:]+\"_\"+df[\"INV\"].str[-1]\n",
					"\n",
					"    dfc=df.groupby(by=[\"Inv\",\"Hour\"]).agg(\"max\").reset_index()\n",
					"\n",
					"    dfc_final=dfc.copy()\n",
					"    dfc_final=dfc_final[[\"Date\",\"Hour\",\"Minute\",\"itemname\",\"Inv\",\"value\"]]\n",
					"    dfc1=dfc_final.groupby(by=[\"Inv\"]).agg(\"max\").reset_index()\n",
					"\n",
					"    dfc1=pd.merge(df_final_new_columns2,dfc1,on=\"Inv\")\n",
					"    missing_inverters_tags=[ (\"ICR\"+str(i[1:3])+\"..INV\"+str(i[-1])+\".kW\").replace(\"0\",\"\") for i in df_Static[\"Inv\"].to_list() if i not in dfc1[\"Inv\"].to_list()]\n",
					"    missing_inverters_tags\n",
					"\n",
					"    \n",
					"    Inverter_allEfficiencyTags=df_tag['InvEfficiency_%'].to_list()\n",
					"    len(Inverter_allEfficiencyTags)\n",
					"\n",
					"    df1=df1[df1['itemname'].isin(Inverter_allEfficiencyTags)]\n",
					"    len(df1[\"itemname\"].unique())\n",
					"\n",
					"    df1[\"itemname\"]=df1[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:x[0])+\"..INV\"+df1[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:str(x[4])[-1])+\".\"+\"INVERTER_EFFICIENCY\"\n",
					"\n",
					"    Inverter_allacpowerTags=df_tag['InvACPower_kW'].to_list()\n",
					"    len(Inverter_allacpowerTags)\n",
					"\n",
					"    df2=df2[df2['itemname'].isin(Inverter_allacpowerTags)]\n",
					"    len(df2[\"itemname\"].unique())\n",
					"\n",
					"    df2[\"itemname\"]=df2[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:x[0])+\"..INV\"+df2[\"itemname\"].str.replace(\".\",\"..\").str.split(\".\").apply(lambda x:str(x[4])[-1])+\".\"+\"kW\"\n",
					"    df2[df2[\"itemname\"]==\"ICR8..INV4.kW\"]\n",
					"\n",
					"    df1_missing_tag_extract=df1.copy()\n",
					"    df1_missing_tag_extract[\"ICR\"]=df1_missing_tag_extract[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"    df1_missing_tag_extract[\"INV\"]=df1_missing_tag_extract[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"    df1_missing_tag_extract[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"\n",
					"    df1_missing_tag_extract[\"Inv\"]=df1_missing_tag_extract[\"ICR\"].str[0]+df1_missing_tag_extract[\"ICR\"].str[-2:]+\"_\"+df1_missing_tag_extract[\"INV\"].str[-1]\n",
					"    df1_missing_tag_extract\n",
					"\n",
					"    missing_inverters_eff_tags=[ (\"ICR\"+str(i[1:3])+\"..INV\"+str(i[-1])+\".kW\").replace(\"0\",\"\") for i in df_Static[\"Inv\"].to_list() if i not in df1_missing_tag_extract[\"Inv\"].to_list()]\n",
					"    missing_inverters_eff_tags\n",
					"\n",
					"    df2_missing_tag_extract=df2.copy()\n",
					"    df2_missing_tag_extract[\"ICR\"]=df2_missing_tag_extract[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"    df2_missing_tag_extract[\"INV\"]=df2_missing_tag_extract[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"    df2_missing_tag_extract[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"\n",
					"    df2_missing_tag_extract[\"Inv\"]=df2_missing_tag_extract[\"ICR\"].str[0]+df2_missing_tag_extract[\"ICR\"].str[-2:]+\"_\"+df2_missing_tag_extract[\"INV\"].str[-1]\n",
					"    df2_missing_tag_extract\n",
					"\n",
					"    missing_inverters_dc_tags=[ (\"ICR\"+str(i[1:3])+\"..INV\"+str(i[-1])+\".kW\").replace(\"0\",\"\") for i in df_Static[\"Inv\"].to_list() if i not in df2_missing_tag_extract[\"Inv\"].to_list()]\n",
					"    missing_inverters_dc_tags\n",
					"\n",
					"    all_missiing_tag=[]\n",
					"    all_missiing_tag.extend(missing_inverters_tags)\n",
					"    all_missiing_tag.extend(missing_inverters_eff_tags)\n",
					"    all_missiing_tag.extend(missing_inverters_dc_tags)\n",
					"    missing_inveters_tag=list(set(all_missiing_tag))\n",
					"    missing_inverters_tags\n",
					"\n",
					"    import datetime\n",
					"    #data_frame_list_final=[]\n",
					"    #data_frame_inverter_downtime_list_final=[]\n",
					"    \n",
					"    Block_list=[(Block1_list,Radiation_Block1),(Block2_list,Radiation_Block1),(Block3_list,Radiation_Block12),(Block4_list,Radiation_Block12),(Block5_list,Radiation_Block12),(Block6_list,Radiation_Block12),(Block7_list,Radiation_Block12),(Block8_list,Radiation_Block12),(Block9_list,Radiation_Block12),(Block10_list,Radiation_Block12),(Block11_list,Radiation_Block12),(Block12_list,Radiation_Block12)]\n",
					"    for k in range(len(Block_list)):\n",
					"        data_frame_list_final=inverter_downtime_logic(Block_list[k][0],Block_list[k][1],missing_inveters_tag,df,df1,df2)\n",
					"    print(\"Data Frame list length\",len(data_frame_list_final))\n",
					"    columns=[\"itemname\",\"Downtime\",\"up_time\",\"Sleep_time\",\"OperationMinutes\",\"RunningMinutes\",\"Average_Efficiency\",\"Max_Efficiency\",\"EnergyLoss\"]\n",
					"    df_main1=pd.DataFrame(data_frame_list_final,columns=columns)\n",
					"    #df_main1['Date'] = df_main1['Date'].astype('datetime64[ns]')\n",
					"    #df_main1.to_excel(\"InverterT2ExtensioB2.xlsx\")\n",
					"\n",
					"    columns1=[\"Date\",\"Inv\",\"Down_From\",\"Down_To\",\"Minutes\"]\n",
					"    df_main2=pd.DataFrame(data_frame_inverter_downtime_list_final,columns=columns1)\n",
					"\n",
					"    df_main2=df_main2[df_main2[\"Minutes\"]!=0]\n",
					"    df_main2\n",
					"\n",
					"    if len(df_main2)!=0:\n",
					"        df_spark3=spark.createDataFrame(df_main2)\n",
					"        spark.sql(\"create database if not exists bkn\")\n",
					"        df_spark3.write.format(\"delta\").mode(\"append\").saveAsTable(\"bkn.invdowntime\")\n",
					"\n",
					"    df_main1[\"ICR\"]=df_main1[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"    df_main1[\"INV\"]=df_main1[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"    ICR_dict={\"ICR1\":\"ICR01\",\n",
					"            \"ICR2\":\"ICR02\",\n",
					"            \"ICR3\":\"ICR03\",\n",
					"            \"ICR4\":\"ICR04\",\n",
					"            \"ICR5\":\"ICR05\",\n",
					"            \"ICR6\":\"ICR06\",\n",
					"            \"ICR7\":\"ICR07\",\n",
					"            \"ICR8\":\"ICR08\",\n",
					"            \"ICR9\":\"ICR09\"}\n",
					"    df_main1[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"\n",
					"    df_main1[\"Inv\"]=df_main1[\"ICR\"].str[0]+df_main1[\"ICR\"].str[-2:]+\"_\"+df_main1[\"INV\"].str[-1]\n",
					"\n",
					"    Table2_Final=pd.merge(dfc1,df_main1,on=\"Inv\",how=\"inner\")\n",
					"\n",
					"    Table2_Final = Table2_Final.rename(columns={'value': 'Inverter_Energy'})\n",
					"\n",
					"    Table2_Final.columns\n",
					"\n",
					"    Table2_Final=Table2_Final[[\"Date\",\"itemname_x\",\"Inv\",\"Inverter_Energy\",'InvUnit1Energy_kWh', 'InvUnit2Energy_kWh', 'InvUnit1Temp_DegC',\n",
					"        'InvUnit2Temp_DegC', 'InvUnit1ACPower_kW', 'InvUnit2ACPower_kW',\n",
					"        'InvACPower_kW', 'InvUnit1DCPower_kW', 'InvUnit2DCPower_kW',\n",
					"        'InvDCPower_kW', 'InvUnit1Efficiency_%', 'InvUnit2Efficiency_%',\n",
					"        'InvApparentPower_kVA', 'InvUnit1ReactivePower_kVAR',\n",
					"        'InvReactivePower_kVAR', 'InvUnit2ReactivePower_kVAR',\n",
					"        'InvUnit1PowerFactor_%', 'InvUnit1PowerFactor_%.1', 'InvPowerFactor_%',\n",
					"        'XformerWTI_DegC',\"Downtime\",\"up_time\",\"Sleep_time\",\"OperationMinutes\",\"RunningMinutes\",\"Average_Efficiency\",\"Max_Efficiency\",\"EnergyLoss\"]]\n",
					"    Table2_Final = Table2_Final.rename(columns={'itemname_x': 'itemname',\n",
					"                                            'Inverter_Energy':'InvEnergy',\n",
					"                                            'Downtime':'InvDowntime',\n",
					"                                            'up_time':'InvWakeUp',\n",
					"                                            'Sleep_time':'InvSleep',\n",
					"                                            'OperationMinutes':'InvOperationMinutes',\n",
					"                                            'RunningMinutes':'InvRunningMinutes',\n",
					"                                            'Average_Efficiency':'InvAvgEff',\n",
					"                                            'Max_Efficiency':'InvMaxEff',\n",
					"                                            'EnergyLoss':'InvEnergyLoss'})\n",
					"\n",
					"    Table2_Final.to_excel(\"abfss://nucleus@ayanadatalake.dfs.core.windows.net/Bkn/inverter_Bkn.xlsx\")\n",
					"\n",
					"    Table2_Final.dtypes\n",
					"\n",
					"    Table2_Final[\"InvDowntime\"]=Table2_Final[\"InvDowntime\"].astype(\"float64\")\n",
					"\n",
					"    if len(missing_inverters_tags)>0:\n",
					"        each_tag_list_missing_tag=[]\n",
					"        for i in missing_inverters_tags:\n",
					"            msg_list=[str(DateList[0]),i,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,\"00:00:00.000\",\"00:00:00.000\",0.0,0.0,0.0,0.0,0.0]\n",
					"            each_tag_list_missing_tag.append(msg_list)\n",
					"\n",
					"    df_missing_tag_colums=Table2_Final.columns.to_list()\n",
					"    df_missing_tag_colums.remove(\"Inv\")\n",
					"    df_missing_tag_colums\n",
					"\n",
					"    if len(missing_inverters_tags)>0:\n",
					"        df_missing_tag=pd.DataFrame(each_tag_list_missing_tag,columns=df_missing_tag_colums)\n",
					"        df_missing_tag\n",
					"        df_missing_tag[\"itemname\"]=df_missing_tag[\"itemname\"].str.split(\".\").apply(lambda x:x[0]+\"..\"+x[2]+\".TODAY_GEN\")\n",
					"        df_missing_tag\n",
					"        df_missing_tag[\"ICR\"]=df_missing_tag[\"itemname\"].apply(lambda x:x.split(\"..\")[0])\n",
					"        df_missing_tag[\"INV\"]=df_missing_tag[\"itemname\"].apply(lambda x:x.split(\"..\")[1].split('.')[0])\n",
					"        ICR_dict={\"ICR1\":\"ICR01\",\n",
					"            \"ICR2\":\"ICR02\",\n",
					"            \"ICR3\":\"ICR03\",\n",
					"            \"ICR4\":\"ICR04\",\n",
					"            \"ICR5\":\"ICR05\",\n",
					"            \"ICR6\":\"ICR06\",\n",
					"            \"ICR7\":\"ICR07\",\n",
					"            \"ICR8\":\"ICR08\",\n",
					"            \"ICR9\":\"ICR09\"}\n",
					"        df_missing_tag[\"ICR\"].replace(ICR_dict,inplace=True)\n",
					"\n",
					"        df_missing_tag[\"Inv\"]=df_missing_tag[\"ICR\"].str[0]+df_missing_tag[\"ICR\"].str[-2:]+\"_\"+df_missing_tag[\"INV\"].str[-1]\n",
					"        Table2_Final_columns=Table2_Final.columns.to_list()\n",
					"        Table2_Final_columns\n",
					"        df_missing_tag=df_missing_tag[Table2_Final_columns]\n",
					"        df_missing_tag\n",
					"        Table2_Final=Table2_Final.append(df_missing_tag)\n",
					"        Table2_Final[\"Date\"]=Table2_Final[\"Date\"].astype(\"datetime64[ns]\")\n",
					"\n",
					"    Table2_Final\n",
					"\n",
					"    Table2_Final[\"InvUnit1Energy_kWh\"]=Table2_Final[\"InvUnit1Energy_kWh\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit2Energy_kWh\"]=Table2_Final[\"InvUnit2Energy_kWh\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1Temp_DegC\"]=Table2_Final[\"InvUnit1Temp_DegC\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit2Temp_DegC\"]=Table2_Final[\"InvUnit2Temp_DegC\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1ACPower_kW\"]=Table2_Final[\"InvUnit1ACPower_kW\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit2ACPower_kW\"]=Table2_Final[\"InvUnit2ACPower_kW\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvACPower_kW\"]=Table2_Final[\"InvACPower_kW\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1DCPower_kW\"]=Table2_Final[\"InvUnit1DCPower_kW\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit2DCPower_kW\"]=Table2_Final[\"InvUnit2DCPower_kW\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvDCPower_kW\"]=Table2_Final[\"InvDCPower_kW\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1Efficiency_%\"]=Table2_Final[\"InvUnit1Efficiency_%\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit2Efficiency_%\"]=Table2_Final[\"InvUnit2Efficiency_%\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvApparentPower_kVA\"]=Table2_Final[\"InvApparentPower_kVA\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1ReactivePower_kVAR\"]=Table2_Final[\"InvUnit1ReactivePower_kVAR\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvReactivePower_kVAR\"]=Table2_Final[\"InvReactivePower_kVAR\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit2ReactivePower_kVAR\"]=Table2_Final[\"InvUnit2ReactivePower_kVAR\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1PowerFactor_%\"]=Table2_Final[\"InvUnit1PowerFactor_%\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvUnit1PowerFactor_%.1\"]=Table2_Final[\"InvUnit1PowerFactor_%.1\"].astype(\"float64\")\n",
					"    Table2_Final[\"InvPowerFactor_%\"]=Table2_Final[\"InvPowerFactor_%\"].astype(\"float64\")\n",
					"    Table2_Final[\"XformerWTI_DegC\"]=Table2_Final[\"XformerWTI_DegC\"].astype(\"float64\")\n",
					"\n",
					"    Table2_Final[Table2_Final[\"Inv\"]==\"I12_4\"]\n",
					"    Table2_Final[\"Time_Interval\"]=str(Batch_Start)+\"_\"+str(Batch_finish)\n",
					"\n",
					"\n",
					"    Table2_Final.dtypes\n",
					"\n",
					"    #location_output = \"abfss://repono@ayanadatalake.dfs.core.windows.net/inverterPerf/\"\n",
					"    #Table2_Final.to_excel(location_output+\"inverter.xlsx\",index=False)\n",
					"\n",
					"    from pyspark.sql.types import StructType,StructField,StringType,DateType,FloatType,LongType,DoubleType\n",
					"    schema=StructType([\n",
					"                        StructField(\"Date\",DateType()),\n",
					"                        StructField(\"itemname\",StringType()),\n",
					"                        StructField(\"Inv\",StringType()),\n",
					"                        StructField(\"InvEnergy\",FloatType()),\n",
					"                        StructField(\"InvUnit1Energy_kWh\",FloatType()),\n",
					"                        StructField(\"InvUnit2Energy_kWh\",FloatType()),\n",
					"                        StructField(\"InvUnit1Temp_DegC\",FloatType()),\n",
					"                        StructField(\"InvUnit2Temp_DegC\",FloatType()),\n",
					"                        StructField(\"InvUnit1ACPower_kW\",FloatType()),\n",
					"                        StructField(\"InvUnit2ACPower_kW\",FloatType()),\n",
					"                        StructField(\"InvACPower_kW\",FloatType()),\n",
					"                        StructField(\"InvUnit1DCPower_kW\",FloatType()),\n",
					"                        StructField(\"InvUnit2DCPower_kW\",FloatType()),\n",
					"                        StructField(\"InvDCPower_kW\",FloatType()),\n",
					"                        StructField(\"InvUnit1Efficiency_%\",FloatType()),\n",
					"                        StructField(\"InvUnit2Efficiency_%\",FloatType()),\n",
					"                        StructField(\"InvApparentPower_kVA\",FloatType()),\n",
					"                        StructField(\"InvUnit1ReactivePower_kVAR\",FloatType()),\n",
					"                        StructField(\"InvReactivePower_kVAR\",FloatType()),\n",
					"                        StructField(\"InvUnit2ReactivePower_kVAR\",FloatType()),\n",
					"                        StructField(\"InvUnit1PowerFactor_%\",FloatType()),\n",
					"                        StructField(\"InvUnit1PowerFactor_%.1\",FloatType()),\n",
					"                        StructField(\"InvPowerFactor_%\",FloatType()),\n",
					"                        StructField(\"XformerWTI_DegC\",FloatType()),\n",
					"                        StructField(\"InvDowntime\",DoubleType()),\n",
					"                        StructField(\"InvWakeUp\",StringType()),\n",
					"                        StructField(\"InvSleep\",StringType()),\n",
					"                        StructField(\"InvOperationMinutes\",DoubleType()),\n",
					"                        StructField(\"InvRunningMinutes\",DoubleType()),\n",
					"                        StructField(\"InvAvgEff\",DoubleType()),\n",
					"                        StructField(\"InvMaxEff\",DoubleType()),\n",
					"                        StructField(\"InvEnergyLoss\",DoubleType()),\n",
					"                        StructField(\"Time_Interval\",StringType()),\n",
					"    ])\n",
					"\n",
					"    Table2_Final\n",
					"\n",
					"    df_spark2=spark.createDataFrame(Table2_Final,schema=schema)\n",
					"    spark.sql(\"create database if not exists bkn\")\n",
					"    df_spark2.write.format(\"delta\").mode(\"append\").saveAsTable(\"bkn.bkninvperformance\")\n",
					"        "
				],
				"execution_count": 244
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"for i in time_batch_list_interval:\n",
					"    data_frame_list_final=[]\n",
					"    data_frame_inverter_downtime_list_final=[]\n",
					"    time_batch_list(i[0],i[1])"
				],
				"execution_count": 245
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"len(data_frame_list_final)"
				],
				"execution_count": 246
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data_frame_list_final"
				],
				"execution_count": 247
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data_frame_inverter_downtime_list_final"
				],
				"execution_count": 248
			}
		]
	}
}